{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 162 of the file /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves.cPickle import load\n",
    "import cPickle\n",
    "import numpy as np\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "from snorkel.parser import XMLMultiDocPreprocessor, CorpusParser\n",
    "from snorkel.parser.spacy_parser import Spacy\n",
    "from snorkel.parser.corenlp import StanfordCoreNLPServer\n",
    "from snorkel.models import Document, Sentence, Candidate, candidate_subclass\n",
    "from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "from snorkel.annotations import LabelAnnotator, load_gold_labels, FeatureAnnotator, save_marginals, load_marginals\n",
    "from snorkel.learning import SparseLogisticRegression, GenerativeModel, RandomSearch, ListParameter, RangeParameter\n",
    "from snorkel.learning.structure import DependencySelector\n",
    "from snorkel.learning.utils import MentionScorer\n",
    "# from snorkel.contrib.rnn import reRNN\n",
    "\n",
    "import matchers\n",
    "import LF\n",
    "from candidate_adjective_fixer import *\n",
    "from load_external_annotations_new import load_external_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#------------------\n",
    "# Helper Functions\n",
    "#------------------\n",
    "\n",
    "def grabCandidates(extractor, schema):\n",
    "    # Candidate Counts\n",
    "    for k, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "        extractor.apply(sents, split=k, clear=False)\n",
    "        print \"Number of candidates: \", session.query(schema).filter(schema.split == k).count()\n",
    "        session.commit()\n",
    "        \n",
    "    train_cands = session.query(schema).filter(\n",
    "        schema.split == 0).all()\n",
    "    dev_cands = session.query(schema).filter(\n",
    "        schema.split == 1).all()\n",
    "    test_cands = session.query(schema).filter(\n",
    "        schema.split == 2).all()\n",
    "\n",
    "    return [train_cands, dev_cands, test_cands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) database is locked [SQL: u'DELETE FROM context']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6e143fbd38c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Note: Parallelism can be run with a Postgres DBMS, but not SQLite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mcorpus_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_preprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mcorpus_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_preprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mcorpus_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/Documents/markerville-backend/markerville-backend/snorkel/snorkel/udf.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, xs, clear, parallelism, progress_bar, count, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mSnorkelSession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sessionmaker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSnorkelSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/Documents/markerville-backend/markerville-backend/snorkel/snorkel/parser/corpus_parser.pyc\u001b[0m in \u001b[0;36mclear\u001b[0;34m(self, session, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m                                            fn=fn)\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# We cannot cascade up from child contexts to parent Candidates,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# so we delete all Candidates too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/sqlalchemy/orm/query.pyc\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, synchronize_session)\u001b[0m\n\u001b[1;32m   3210\u001b[0m         delete_op = persistence.BulkDelete.factory(\n\u001b[1;32m   3211\u001b[0m             self, synchronize_session)\n\u001b[0;32m-> 3212\u001b[0;31m         \u001b[0mdelete_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdelete_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/sqlalchemy/orm/persistence.pyc\u001b[0m in \u001b[0;36mexec_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_pre_synchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_post_synchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/sqlalchemy/orm/persistence.pyc\u001b[0m in \u001b[0;36m_do_exec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0mdelete_stmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m             mapper=self.mapper)\n\u001b[0m\u001b[1;32m   1364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/sqlalchemy/orm/session.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, clause, params, mapper, bind, **kw)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         return self._connection_for_bind(\n\u001b[0;32m-> 1139\u001b[0;31m             bind, close_with_result=True).execute(clause, params or {})\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclause\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object, *multiparams, **params)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/sqlalchemy/sql/elements.pyc\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_clauseelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params)\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0mcompiled_sql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m             \u001b[0mcompiled_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistilled_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         )\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m                 context)\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1400\u001b[0m                 util.raise_from_cause(\n\u001b[1;32m   1401\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m                     \u001b[0mexc_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m                 )\n\u001b[1;32m   1404\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/sqlalchemy/util/compat.pyc\u001b[0m in \u001b[0;36mraise_from_cause\u001b[0;34m(exception, exc_info)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mcause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpy3k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                         \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                         \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                         context)\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             self._handle_dbapi_exception(\n",
      "\u001b[0;32m/Users/gmachiraju/py2_kernel/lib/python2.7/site-packages/sqlalchemy/engine/default.pyc\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) database is locked [SQL: u'DELETE FROM context']"
     ]
    }
   ],
   "source": [
    "#-----------------------\n",
    "# Setup & Preprocessing\n",
    "#-----------------------\n",
    "\n",
    "# Instantiate the Session\n",
    "session = SnorkelSession()\n",
    "session.rollback()\n",
    "# Doc Preprocessing\n",
    "file_path = 'articles/training.xml'\n",
    "train_preprocessor = XMLMultiDocPreprocessor(\n",
    "    path=file_path,\n",
    "    doc='.//article',\n",
    "    text='.//front/article-meta/abstract/p/text()',\n",
    "    id='.//front/article-meta/article-id/text()'\n",
    ")\n",
    "\n",
    "file_path = 'articles/development.xml'\n",
    "dev_preprocessor = XMLMultiDocPreprocessor(\n",
    "    path=file_path,\n",
    "    doc='.//document',\n",
    "    text='.//passage/text/text()',\n",
    "    id='.//id/text()'\n",
    ")\n",
    "\n",
    "file_path = 'articles/testcorpus.xml'\n",
    "test_preprocessor = XMLMultiDocPreprocessor(\n",
    "    path=file_path,\n",
    "    doc='.//document',\n",
    "    text='.//passage/text/text()',\n",
    "    id='.//id/text()'\n",
    ")\n",
    "\n",
    "# Parsing\n",
    "# corenlp_server = StanfordCoreNLPServer(version=\"3.6.0\", num_threads=4, port=12348)\n",
    "# corpus_parser = CorpusParser(corenlp_server, parser=Spacy())\n",
    "corpus_parser = CorpusParser(parser=Spacy())\n",
    "# corpus_parser = CorpusParser()\n",
    "\n",
    "# Note: Parallelism can be run with a Postgres DBMS, but not SQLite\n",
    "corpus_parser.apply(list(train_preprocessor))\n",
    "corpus_parser.apply(list(dev_preprocessor), clear=False)\n",
    "corpus_parser.apply(list(test_preprocessor), clear=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving Stable IDs for each of the candidate sentences\n",
    "with open('articles/doc_ids.pkl', 'rb') as f:\n",
    "    train_ids, dev_ids, test_ids = load(f)\n",
    "\n",
    "train_ids, dev_ids, test_ids = set(train_ids), set(dev_ids), set(test_ids)\n",
    "train_sents, dev_sents, test_sents = set(), set(), set()\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "\n",
    "\n",
    "# Assigning each sentence to {train,dev,test}-set based on Stable ID\n",
    "for i, doc in enumerate(docs):\n",
    "    for s in doc.sentences:\n",
    "        if doc.name in train_ids:\n",
    "            train_sents.add(s)\n",
    "        elif doc.name in dev_ids:\n",
    "            dev_sents.add(s)\n",
    "        elif doc.name in test_ids:\n",
    "            test_sents.add(s)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                'ID <{0}> not found in any id set'.format(doc.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Candidate Extraction\n",
    "#----------------------\n",
    "\n",
    "# Defining the Candidate Schemas\n",
    "BiomarkerCondition = candidate_subclass('BiomarkerCondition', ['biomarker', 'condition'])\n",
    "BiomarkerDrug = candidate_subclass('BiomarkerDrug', ['biomarker', 'drug'])\n",
    "BiomarkerMedium = candidate_subclass('BiomarkerMedium', ['biomarker', 'medium'])\n",
    "BiomarkerType = candidate_subclass('BiomarkerType', ['biomarker', 'typ3'])\n",
    "# BiomarkerLevelUnit = candidate_subclass('BiomarkerLevelUnit', ['biomarker', 'level', 'unit'])\n",
    "#can eventually add MEASUREMENT and COHORT SIZE among other entities\n",
    "\n",
    "# N-grams: the probabilistic search space of our entities\n",
    "biomarker_ngrams = Ngrams(n_max=1)\n",
    "condition_ngrams = Ngrams(n_max=7)\n",
    "drug_ngrams = Ngrams(n_max=5)\n",
    "medium_ngrams = Ngrams(n_max=5)\n",
    "type_ngrams = Ngrams(n_max=5)  # <--- Q: should we cut these down?\n",
    "# level_ngrams = Ngrams(n_max=1)\n",
    "# unit_ngrams = Ngrams(n_max=1)\n",
    "\n",
    "# Construct our Matchers\n",
    "bMatcher = matchers.getBiomarkerMatcher()\n",
    "cMatcher = matchers.getConditionMatcher()\n",
    "dMatcher = matchers.getDrugMatcher()\n",
    "mMatcher = matchers.getMediumMatcher()\n",
    "tMatcher = matchers.getTypeMatcher()\n",
    "# lMatcher = matchers.getLevelMatcher()\n",
    "# uMatcher = matchers.getUnitMatcher()\n",
    "\n",
    "# Building the CandidateExtractors\n",
    "candidate_extractor_BC = CandidateExtractor(BiomarkerCondition, [biomarker_ngrams, condition_ngrams], [bMatcher, cMatcher])\n",
    "cands_BC = grabCandidates(candidate_extractor_BC, BiomarkerCondition)\n",
    "add_adj_candidate_BC(session, BiomarkerCondition, cands_BC[1], 0)\n",
    "session.commit()\n",
    "LFs_BC = [LF_markerDatabase, LF_keyword, LF_distance, LF_abstract_titleWord, LF_single_letter,\n",
    "          LF_auxpass, LF_known_abs, LF_same_thing_BC, LF_common_1000, LF_common_2000]\n",
    "labeler_BC = LabelAnnotator(lfs=LFs_BC)\n",
    "L_train_BC = labeler_BC.apply(split=0)\n",
    "L_train_BC\n",
    "L_train_BC.lf_stats(session)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "candidate_extractor_BD = CandidateExtractor(BiomarkerDrug, [biomarker_ngrams, drug_ngrams], [bMatcher, dMatcher])\n",
    "candidate_extractor_BM = CandidateExtractor(BiomarkerMedium, [biomarker_ngrams, medium_ngrams], [bMatcher, mMatcher])\n",
    "candidate_extractor_BT = CandidateExtractor(BiomarkerType, [biomarker_ngrams, type_ngrams], [bMatcher, tMatcher])\n",
    "# candidate_extractor_BLU = CandidateExtractor(BiomarkerLevelUnit, [biomarker_ngrams, level_ngrams, unit_ngrams], [bMatcher, lMatcher, uMatcher])\n",
    "\n",
    "# List of Candidate Sets for each relation type: [train, dev, test]\n",
    "cands_BD = grabCandidates(candidate_extractor_BD, BiomarkerDrug)\n",
    "cands_BM = grabCandidates(candidate_extractor_BM, BiomarkerMedium)\n",
    "cands_BT = grabCandidates(candidate_extractor_BT, BiomarkerType)\n",
    "# cands_BLU = grabCandidates(candidate_extractor_BLU, BiomarkerLevelUnit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.rollback()\n",
    "\n",
    "# {train,dev,test} is split order\n",
    "\n",
    "# Adjective Boosting - BC\n",
    "print \"Number of dev BC candidates without adj. boosting: \", len(cands_BC[1])\n",
    "add_adj_candidate_BC(session, BiomarkerCondition, cands_BC[1], 0)\n",
    "# fix_specificity(session, BiomarkerCondition, cands_BC[1])\n",
    "print \"Number of dev BC candidates with adj. boosting: \", session.query(BiomarkerCondition).filter(BiomarkerCondition.split == 1).count()\n",
    "session.commit()\n",
    "\n",
    "# Adjective Boosting - BD\n",
    "print \"Number of dev BD candidates without adj. boosting: \", len(cands_BD[1])\n",
    "add_adj_candidate_BD(session, BiomarkerDrug, cands_BD[1], 0)\n",
    "print \"Number of dev BD candidates with adj. boosting: \", session.query(BiomarkerDrug).filter(BiomarkerDrug.split == 1).count()\n",
    "session.commit()\n",
    "\n",
    "# Adjective Boosting - BM\n",
    "print \"Number of dev BM candidates without adj. boosting: \", len(cands_BM[1])\n",
    "add_adj_candidate_BM(session, BiomarkerMedium, cands_BM[1], 0)\n",
    "print \"Number of dev BM candidates with adj. boosting: \", session.query(BiomarkerMedium).filter(BiomarkerMedium.split == 1).count()\n",
    "session.commit()\n",
    "\n",
    "# Adjective Boosting - BT (none as of now)\n",
    "# Adjective Boosting - BLU (none as of now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "# External Gold Labels & Labeling Functions\n",
    "#-------------------------------------------\n",
    "from LF import *\n",
    "# Labeling Functions\n",
    "LFs_BD = [LF_colon, LF_known_abs, LF_single_letter,\n",
    "          LF_roman_numeral, LF_common_2000, LF_same_thing_BD]\n",
    "LFs_BM = [LF_distance_far, LF_colon, LF_known_abs, LF_single_letter, LF_roman_numeral, LF_common_2000, LF_same_thing]\n",
    "LFs_BT = [LF_colon, LF_known_abs, LF_single_letter, LF_roman_numeral, LF_common_2000, LF_same_thing]\n",
    "\n",
    "labeler_BC = LabelAnnotator(lfs=LFs_BC)\n",
    "labeler_BD = LabelAnnotator(lfs=LFs_BD)\n",
    "labeler_BM = LabelAnnotator(lfs=LFs_BM)\n",
    "labeler_BT = LabelAnnotator(lfs=LFs_BT)\n",
    "\n",
    "# Training\n",
    "L_train_BC = labeler_BC.apply(split=0)\n",
    "L_train_BD = labeler_BD.apply(split=0)\n",
    "L_train_BM = labeler_BM.apply(split=0)\n",
    "L_train_BT = labeler_BT.apply(split=0)\n",
    "L_train_BC\n",
    "L_train_BD\n",
    "L_train_BM\n",
    "L_train_BT\n",
    "\n",
    "# Labeling Function Performance - Coverage, Overlaps, Conflicts\n",
    "L_train_BC.lf_stats(session)\n",
    "L_train_BD.lf_stats(session)\n",
    "L_train_BM.lf_stats(session)\n",
    "L_train_BT.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
